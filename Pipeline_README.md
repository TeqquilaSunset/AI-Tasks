# PDF Pipeline с использованием Ollama и Qdrant

Этот проект реализует пайплайн для обработки PDF файлов, генерации эмбеддингов с помощью Ollama и сохранения их в векторную базу данных Qdrant.

## Структура проекта

- `pdf_pipeline.py` - Основной пайплайн для обработки PDF
- `pdf_pipeline_async.py` - Асинхронная версия пайплайна с оптимизацией для GPU
- `run_pipeline_gpu.py` - Скрипт для оптимизированного запуска с GPU
- `requirements.txt` - Зависимости проекта
- `GPU_SETUP.md` - Инструкция по настройке GPU для максимальной производительности
- `test_pdf_pipeline.py` - Тестовый скрипт
- `test_async_pipeline.py` - Тестовый скрипт для асинхронной версии

## Установка

1. Установите все зависимости:
```
pip install -r requirements.txt
```

2. Установите и запустите Ollama с поддержкой GPU (см. GPU_SETUP.md)

3. Убедитесь, что Qdrant запущен на `http://localhost:6333`

## Использование

### Простой запуск:
```
python pdf_pipeline.py --pdf_path path/to/your/file.pdf
```

### Асинхронный пайплайн (рекомендуется для GPU):
```
python pdf_pipeline_async.py --pdf_path path/to/your/file.pdf --max_concurrent 10
```

### Оптимизированный запуск для GPU:
```
python run_pipeline_gpu.py --pdf_path path/to/your/file.pdf --use_async --max_concurrent 15
```

### Доступные параметры:

- `--pdf_path` (обязательный): Путь к обрабатываемому PDF файлу
- `--chunk_size`: Размер чанка текста (по умолчанию 1024/2048 для GPU)
- `--overlap`: Перекрытие между чанками (по умолчанию 50)
- `--collection_name`: Название коллекции в Qdrant (по умолчанию pdf_chunks)
- `--embedding_model`: Используемая модель Ollama (по умолчанию qwen3-embedding:latest)
- `--ollama_host`: Адрес API Ollama (по умолчанию http://localhost:11434)
- `--max_concurrent` (для асинхронной версии): Количество одновременных запросов (по умолчанию 10, рекомендуется 15 для RTX 4070)
- `--use_async` (для run_pipeline_gpu.py): Использовать асинхронную версию (по умолчанию False)

## Оптимизация для GPU

Для максимальной производительности с видеокартой NVIDIA RTX 4070, следуйте инструкциям в `GPU_SETUP.md`:

1. Установите CUDA Toolkit и драйверы
2. Запустите Ollama с настройками GPU
3. Используйте асинхронную версию пайплайна с оптимальным значением `--max_concurrent`
4. Рекомендуется использовать `python run_pipeline_gpu.py --use_async --max_concurrent 15`

## Асинхронная обработка

Асинхронная версия пайплайна позволяет:
- Отправлять несколько запросов к Ollama одновременно
- Лучше использовать вычислительные ресурсы видеокарты
- Значительно ускорить генерацию эмбеддингов
- Использовать семафоры для контроля нагрузки

## Как это работает

1. **Разбиение PDF**: Файл читается и разбивается на чанки с возможным перекрытием
2. **Генерация эмбеддингов**: Каждый чанк отправляется в Ollama для получения векторного представления
3. **Сохранение в Qdrant**: Эмбеддинги и метаданные сохраняются в векторную базу данных Qdrant

## Файлы проекта

- `pdf_pipeline.py`: Синхронная реализация пайплайна
- `pdf_pipeline_async.py`: Асинхронная версия с оптимизацией для параллельной обработки
- `run_pipeline_gpu.py`: Удобный скрипт для запуска с GPU-оптимизациями
- `test_pdf_pipeline.py`: Тестовый скрипт для проверки работы компонентов
- `test_async_pipeline.py`: Тестовый скрипт для асинхронной версии
- `requirements.txt`: Зависимости проекта
- `GPU_SETUP.md`: Руководство по настройке GPU
- `Pipeline_README.md`: Этот файл