# Настройка Ollama для использования GPU (NVIDIA RTX 4070)

Для максимальной производительности при генерации эмбеддингов с помощью Ollama и вашей видеокарты NVIDIA RTX 4070, выполните следующие шаги:

## 1. Установка необходимых компонентов

### Установите CUDA Toolkit
- Скачайте и установите последнюю версию CUDA Toolkit с [официального сайта NVIDIA](https://developer.nvidia.com/cuda-downloads)
- Убедитесь, что версия драйвера вашей видеокарты поддерживает устанавливаемую версию CUDA

### Установите Ollama с поддержкой CUDA
- Убедитесь, что вы используете версию Ollama, собранную с поддержкой CUDA
- На Windows вы можете установить Ollama через официальный установщик с сайта ollama.com

## 2. Проверка установки GPU

Проверьте, что CUDA и драйверы установлены правильно:
```
nvidia-smi
```

## 3. Запуск Ollama с использованием GPU

Запустите Ollama с настройками, оптимизированными под вашу видеокарту:

```bash
# Установите переменные окружения для использования GPU
set OLLAMA_NUM_PARALLEL=10
set OLLAMA_MAX_LOADED_MODELS=2
set OLLAMA_NOHISTORY=1

# Если вы хотите ограничить использование памяти (например, для 12GB VRAM)
# set OLLAMA_GPU_MEMORY=10240

# Запустите Ollama
ollama serve
```

или используя PowerShell:
```powershell
$env:OLLAMA_NUM_PARALLEL=10
$env:OLLAMA_MAX_LOADED_MODELS=2
$env:OLLAMA_NOHISTORY=1
ollama serve
```

## 4. Оптимизация производительности для RTX 4070

### Установка системных переменных для лучшей производительности:
- `OLLAMA_NUM_PARALLEL` - количество параллельных запросов (рекомендуется 8-12 для RTX 4070)
- `OLLAMA_MAX_LOADED_MODELS` - количество загруженных моделей в памяти (рекомендуется 2-3)
- `OLLAMA_GPU_MEMORY` - ограничение GPU памяти в MB (до 10240 для RTX 4070 с 12GB)

### Пример настройки для RTX 4070:
```bash
set OLLAMA_NUM_PARALLEL=10
set OLLAMA_MAX_LOADED_MODELS=2
set OLLAMA_NOHISTORY=1
set OLLAMA_GPU_MEMORY=10240
ollama serve
```

## 5. Использование асинхронной версии пайплайна

Для максимального использования GPU используйте асинхронную версию пайплайна:

```bash
python pdf_pipeline_async.py --pdf_path your_file.pdf --max_concurrent 10
```

Параметр `--max_concurrent` определяет количество одновременных запросов к Ollama. Для RTX 4070 рекомендуется значение от 8 до 15.

## 6. Мониторинг использования GPU

Для мониторинга использования видеокарты во время работы используйте:
```bash
nvidia-smi -l 1
```

Это покажет обновления каждые 1 секунду, чтобы вы видели, как используется GPU память и вычислительные ресурсы.

## 7. Рекомендации по производительности

- Увеличьте `chunk_size` до 2048 или 4096 для меньшего количества запросов
- Увеличьте `max_concurrent` до 15-20 для лучшего использования GPU
- Используйте асинхронную версию (`pdf_pipeline_async.py`) для параллельной обработки
- Увеличьте размер батча в Qdrant до 1000 для более быстрой загрузки данных

## 8. Запуск с максимальной производительностью

Пример полностью оптимизированной команды:
```bash
python pdf_pipeline_async.py --pdf_path your_file.pdf --chunk_size 2048 --max_concurrent 15 --collection_name your_collection
```

## Заключение

После настройки Ollama для использования вашей RTX 4070, вы должны увидеть значительное увеличение скорости генерации эмбеддингов. Асинхронная версия пайплайна особенно эффективна, так как позволяет лучше использовать вычислительные ресурсы видеокарты за счет параллельной обработки нескольких запросов.